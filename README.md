```
1. Ответ:
Я бы сделал так
1. 
Получаю текущую операцию ID через db.currentOp()
Убиваю opp через db.killOp()

2.
с помощью MaxTimeMS можно сделать автоматическую отмену запросов, это улучшит использование ресурсов.

Следовательно с помощью MaxTimeMS могу указать, сколько позолено выполнять запрос.

Пример:
db.collection.find({
  // my query
}).maxTimeMS(100)

Ограничение в 100 мс

```
``` 
2.Ответ:
Думаю вся память забилась истекшими ключами, но еще не удаленными. 
Redis заблокировался, чтобы снизить кол-во ключей менее 25%.
О лечении тут:
Latency generated by expires
Redis evict expired keys in two ways:
One lazy way expires a key when it is requested by a command, but it is found to be already expired.
One active way expires a few keys every 100 milliseconds.
The active expiring is designed to be adaptive. An expire cycle is started every 100 milliseconds (10 times per second), and will do the following:
Sample ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP keys, evicting all the keys already expired.
If the more than 25% of the keys were found expired, repeat.
Given that ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP is set to 20 by default, and the process is performed ten times per second, usually just 200 keys per second are actively expired. This is enough to clean the DB fast enough even when already expired keys are not accessed for a long time, so that the lazy algorithm does not help. At the same time expiring just 200 keys per second has no effects in the latency a Redis instance.
However the algorithm is adaptive and will loop if it finds more than 25% of keys already expired in the set of sampled keys. But given that we run the algorithm ten times per second, this means that the unlucky event of more than 25% of the keys in our random sample are expiring at least in the same second.
Basically this means that if the database has many many keys expiring in the same second, and these make up at least 25% of the current population of keys with an expire set, Redis can block in order to get the percentage of keys already expired below 25%.
This approach is needed in order to avoid using too much memory for keys that are already expired, and usually is absolutely harmless since it's strange that a big number of keys are going to expire in the same exact second, but it is not impossible that the user used EXPIREAT extensively with the same Unix time.
In short: be aware that many keys expiring at the same moment can be a source of latency.


```
```
3.Ответ:
Предположу данные не успевают передаться.
Естественно конкретизировать проблему через лог. Дальше по ситуации сначал бы корректировал параметры:
net_read_timeout, connect_timeout, max_allowed_packet в my.cnf

```
```
4. Ответ:
Если запускается oom-killer, то проблема в малом кол-ве памяти. Лучшее решение - добавить оперативки.
Если возможности нет, то изменить конфиг postgresql:
work_mem
shared_buffers
effective_cache_size
maintenance_work_mem
 
```
